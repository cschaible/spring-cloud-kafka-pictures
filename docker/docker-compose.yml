version: '2.1'

services:
  mongodb1:
    container_name: mongodb1
    hostname: mongodb1
    build: ./mongodb
    ports:
      - "127.0.0.1:27017:27017"
    volumes:
      - ./mongo-initdb.d:/docker-entrypoint-initdb.d
    command: --sslMode disabled --bind_ip_all --replSet rs_showcase
    healthcheck:
      test: "nc -z 127.0.0.1 27017 || exit 1"
      interval: 3s
      retries: 100
  
  mongodb2:
    container_name: mongodb2
    hostname: mongodb2
    build: ./mongodb
    ports:
      - "127.0.0.2:27017:27017"
    command: --sslMode disabled --bind_ip_all --replSet rs_showcase
    healthcheck:
      test: "nc -z 127.0.0.1 27017 || exit 1"
      interval: 3s
      retries: 100
  
  cassandra:
    image: cassandra:3.11
    container_name: cassandra
    hostname: cassandra
    ports:
      - "9042:9042"
  
  elasticsearch:
    # Ensure that vm.max_map_count is large enough
    # On linux systems with system.d run: sudo sysctl -w vm.max_map_count=262144
    # Or create a file 60-elasticsearch.conf in /etc/sysctl.d/ with the content
    # vm.max_map_count=262144
    # More details: https://github.com/spujadas/elk-docker/issues/89#issuecomment-261419109
    image: docker.elastic.co/elasticsearch/elasticsearch:6.8.1
    container_name: elasticsearch
    hostname: elasticsearch
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
      - "9300:9300"
    healthcheck:
      test: "nc -z 127.0.0.1 9200 || exit 1"
      interval: 3s
      retries: 100

  elastichq:
    image: elastichq/elasticsearch-hq
    container_name: elastichq
    hostname: elastichq
    environment:
      - "HQ_DEFAULT_URL=http://elasticsearch:9200"
    ports:
      - "5010:5000"
    healthcheck:
      test: "nc -z 127.0.0.1 5000 || exit 1"
      interval: 3s
      retries: 100

  user-mysql:
    container_name: user-mysql
    hostname: user-mysql
    image: mysql:5
    environment:
      - MYSQL_ROOT_PASSWORD=secret
      - MYSQL_DATABASE=user
      - MYSQL_USER=mysql
      - MYSQL_PASSWORD=secret
    ports:
      - "3307:3306"
    healthcheck:
      test: "nc -z 127.0.0.1 3306 || exit 1"
      interval: 3s
      retries: 100
  
  zipkin:
    container_name: zipkin
    hostname: zipkin
    image: openzipkin/zipkin:2
    # Environment settings are defined here https://github.com/openzipkin/zipkin/tree/1.19.0/zipkin-server#environment-variables
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HOSTS=elasticsearch
      - KAFKA_BOOTSTRAP_SERVERS=broker:9092
    ports:
      - "9412:9411"
    depends_on:
      broker:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: "nc -z 127.0.0.1 9411 || exit 1"
      interval: 3s
      retries: 100
        
  zipkin-dependencies:
    container_name: zipkin-dependencies
    hostname: zipkin-dependencies
    image: openzipkin/zipkin-dependencies:2
    entrypoint: crond -f
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HOSTS=elasticsearch
    depends_on:
      elasticsearch:
        condition: service_healthy

  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:5.3.0
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000

  broker:
    container_name: kafka-broker
    hostname: broker
    image: confluentinc/cp-kafka:5.3.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://broker:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_NUM_PARTITIONS=3
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - CONFLUENT_SUPPORT_METRICS_ENABLED=false
    healthcheck:
      test: "nc -z 127.0.0.1 9092 || exit 1"
      interval: 3s
      retries: 100

  schema-registry:
    container_name: kafka-schema-registry
    image: confluentinc/cp-schema-registry:5.3.0
    depends_on:
     - zookeeper
     - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: 'schema-registry'
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_URL_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,DELETE,OPTIONS,HEAD'

  kafka-rest-proxy:
    container_name: kafka-rest-proxy
    image: confluentinc/cp-kafka-rest:5.3.0
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_REST_LISTENERS: 'http://kafka-rest-proxy:8082' 
      KAFKA_REST_HOST_NAME: 'kafka-rest-proxy'
      KAFKA_REST_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      KAFKA_REST_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,DELETE,OPTIONS,HEAD'

  kafka-topics-ui:
    container_name: kafka-topics-ui
    image: landoop/kafka-topics-ui:0.9.4
    ports:
      - "8000:8000"
    environment:
      KAFKA_REST_PROXY_URL: 'http://localhost:8082'
